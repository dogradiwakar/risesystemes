<!doctype html>
<html amp lang="en">
  
<!-- Mirrored from www.redapt.com/blog/apache-spark-for-machine-learning-part-1?hs_amp=true by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2020 06:51:19 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <title>Apache Spark for Machine Learning - Part 1</title>
    <link rel="canonical" href="apache-spark-for-machine-learning-part-1.html" />
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <meta name="author" content="Christoph Champ">

    <meta name="description" content="Apache Spark is fast, easy to use, and a general engine for large-scale data processing and analysis. It provides parallel distributed processing on commodity hardware. It provides a comprehensive, unified framework for Big Data analytics.">

    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

    <meta name="generator" content="HubSpot">
    <script type="application/ld+json">
      {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Apache Spark for Machine Learning - Part 1",
        "datePublished": "2017-03-10T00:00:00Z",
        "dateModified": "2020-08-24T18:43:54.227Z",
        "mainEntityOfPage": "https://www.redapt.com/blog/apache-spark-for-machine-learning-part-1",
        "author": {
          "@type": "Person",
          "name": "Christoph Champ"
        },
        "image": {
         "@type": "ImageObject",
        
          
          "width": 650,
          
          
          "height": 430,
          
          "url": "https://cdn2.hubspot.net/hubfs/6151115/Imported_Blog_Media/595437d5491eed0808d50677_apache-spark-1.png"
        
        },
        "publisher" : {
          "@type": "Organization",
          "logo": {
            "@type": "ImageObject",
            
            "url": "https://cdn2.hubspot.net/hubfs/6151115/Redapt_August2019/Images/logo.svg",
            "width": 60.000004,
            "height": 60.0
            
          },
          "name": "Insights"
        }
      }
    </script>
    <script async custom-element="amp-analytics" src="../../cdn.ampproject.org/v0/amp-analytics-0.1.js"></script>
    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style>
    <noscript>
      <style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style>
    </noscript>
  <style amp-custom>
      body {
        color: #404040;
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
        font-size: 18px;
        line-height: 1.6;
      }

      .hs-page-width-normal {
        box-sizing: content-box;
        margin: 0 auto;
        padding: 0 5vw 5vw;
      }

      .info {
        font-size: 14px
      }

      h1 {
        color: 'Helvetica Neue', Helvetica, Arial, sans-serif;
        font-size: 26px;
        line-height: 1.5;
        font-weight: 600;
      }

      h1 a {
        color: #404040;
      }

      h2 {
        color: #404040;
        font-size: 22px;
        line-height: 38px;
      }

      a {
        color: #416bb3;
        text-decoration: none;
      }

      .logo-header-text {
        color: #1e1e1e;
        font-size: 36px;
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
        line-height: 2.0;
        font-weight: bold;
        vertical-align: text-bottom;
      }

      .hs-page-width-normal {
        padding: 5vw;
      }

      .iframe-placeholder {
        background-color: #bbb;
      }

      .header-banner {
        padding: 3vw 1vw;
        border-color: #dcdcdc;
        border-bottom-style: solid;
        border-bottom-width: thin;
        background-color: #ffffff;
        color: #1e1e1e;
        text-align: center;
      }

      .full-link {
        text-align: center;
      }

      .full-link a {
        border: 1px solid #dcdcdc;
        background-color: transparent;
        color: #416bb3;
        cursor: pointer;
        display: block;
        font-size: 14px;
        line-height: 18px;
        margin: 0 auto;
        max-width: 200px;
        padding: 11px 16px;
        text-decoration: none;
        width: 50%;
      }

    </style></noscript>
    <script async src="../../cdn.ampproject.org/v0.js"></script>
  </head>
  <body>
    <div class="row-fluid">
      <div class="header-banner">
        <a class="blog-link" href="../blog.html">
        
          <span class="logo">
            <amp-img src="https://cdn2.hubspot.net/hubfs/6151115/Redapt_August2019/Images/logo.svg" height="60.0" width="60.000004" alt="logo"></amp-img>
          </span>
        
          <span class="logo-header-text">Insights | Redapt</span>
         </a>
      </div>  
      <div class="hs-page-width-normal">
        <div class="post-header">
          <h1><a href="apache-spark-for-machine-learning-part-1.html">Apache Spark for Machine Learning - Part 1</a></h1>
        </div>
        <div class="info">
          <span> Written by <a class="author-link" href="author/christoph-champ.html">Christoph Champ</a> | Mar 10, 2017 12:00:00 AM </span>
        </div>
        <div class="blog-section">
          <span><p>&nbsp;</p>

<blockquote>
<p>Apache Spark is the Taylor Swift of big data software. The open source technology has been around and popular for a few years. But 2015 was the year Spark went from an ascendant technology to a <a href="http://fortune.com/2015/09/25/apache-spark-survey/">bona fide superstar</a>".</p>
</blockquote>
<p>Apache Spark is an open-source cluster-computing framework. Originally developed at the University of California, Berkeley's&nbsp;AMPLab, the Spark codebase was later donated to the Apache Software Foundation, which has maintained it since. Spark provides an interface for programming entire clusters with implicit data parallelism and fault-tolerance.</p>
<p>Apache Spark is&nbsp;fast, easy to use, and a general engine for large-scale data processing and analysis. It provides parallel distributed processing on commodity hardware. It provides a comprehensive, unified framework for Big Data analytics.</p>
<p>Spark Core is the foundation of the overall project. It provides distributed task dispatching, scheduling, and basic I/O functionalities, exposed through an application programming interface (for Java, Python, Scala, and R) centered on the resilient distributed dataset (RDD).</p>
<p>Spark&nbsp;MLlib&nbsp;is a distributed machine learning framework on top of Spark Core. Many common machine learning and statistical algorithms have been implemented and are shipped with&nbsp;MLlib&nbsp;which simplifies large scale machine learning pipelines. This blog post will focus on&nbsp;MLlib.</p>
<h4>&nbsp;Spark use cases</h4>
<ul>
<li>Fraud detection: Spark streaming and machine learning applied to prevent fraud.</li>
<li>Network intrusion detection: Machine learning applied to detect cyber hacks.</li>
<li>Customer segmentation and personalization: Spark SQL and machine learning applied to maximize customer lifetime value.</li>
<li>Social media sentiment analysis: Spark streaming, Spark SQL, and Stanford's&nbsp;CoreNLP&nbsp;wrapper helps achieve sentiment analysis.</li>
<li>Real-time ad targeting: Spark used to maximize Online ad revenues.</li>
<li>Predictive healthcare: Spark used to optimize healthcare costs.</li>
</ul>
<h4>Real-life examples of Spark in industry</h4>
<h4>Uber</h4>
<ul>
<li>Business Problem: A simple problem of getting people around a city with an army of more than 100,000 drivers and to use data to intelligently perfect the business in an automated and real-time fashion.</li>
<li>Requirements:</li>
<li>Accurately pay drivers per trips in the dataset</li>
<li>Maximize profits by positioning vehicles optimally</li>
<li>Help drivers avoid accidents</li>
<li>Calculate surge pricing</li>
<li>Solution: Use Spark Streaming and Spark SQL as the ELT system and Spark&nbsp;MLlib&nbsp;and&nbsp;GraphX&nbsp;for advanced analytics</li>
<li>Reference: Talk by Uber engineers at Apache Spark&nbsp;meetup:&nbsp;<a href="https://youtu.be/zKbds9ZPjLE">https://youtu.be/zKbds9ZPjLE</a></li>
</ul>
<h4>Netflix</h4>
<ul>
<li>Business Problem: A video streaming service with emphasis on data quality, agility, and availability. Using analytics to help users discover films and TV shows that they like is key to Netflix's success.</li>
<li>Requirements:</li>
<li>Streaming applications are long-running tasks that need to be resilient in Cloud deployments.</li>
<li>Optimize content buying</li>
<li>Maintain Netflix's acclaimed&nbsp;personalization algorithms</li>
<li>Solution: Use Spark Streaming in AWS and Spark&nbsp;GraphX&nbsp;for recommendation system.</li>
<li>Reference: Talk by Netflix engineers at Apache Spark meetup:&nbsp;<a href="https://youtu.be/gqgPtcDmLGs">https://youtu.be/gqgPtcDmLGs</a></li>
</ul>
<h4>&nbsp;Pinterest</h4>
<ul>
<li>Business Problem: Provide a recommendation and visual bookmarking tool that lets users discover, save, and share ideas. Also get an immediate view of Pinterest engagement activity with high-throughput&nbsp;and minimal latency.</li>
<li>Requirements:</li>
<li>Real-time analytics to process user's activity.</li>
<li>Process petabytes of data to provide recommendations and personalization.</li>
<li>Apply sophisticated deep learning techniques to a Pin image in order to suggest related Pins.</li>
<li>Solution: Use Spark Streaming, Spark SQL,&nbsp;MemSSQL's&nbsp;Spark connector for real-time analytics, and Spark&nbsp;MLlib&nbsp;for machine learning use cases.</li>
<li>Reference: <a href="https://medium.com/@Pinterest_Engineering/real-time-analytics-at-pinterest-1ef11fdb1099#.y1cdhb9c3">https://medium.com/@Pinterest_Engineering/real-time-analytics-at-pinterest-1ef11fdb1099#.y1cdhb9c3</a></li>
</ul>
<p>If your company does not have the resources the above companies have to devote to machine learning,&nbsp;Redapt&nbsp;is here to help!</p>
<h4>Spark and its speed</h4>
<ul>
<li>Lightning fast speeds due to in-memory caching and a&nbsp;<a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG-based</a>&nbsp;processing engine.</li>
<li>100 times faster than Hadoop's MapReduce for in-memory computations and 10 time faster for on-disk.</li>
<li>Well suited for iterative algorithms in machine learning.</li>
<li>Fast, real-time response to user queries on large in-memory data sets.</li>
<li>Low latency data analysis applied to processing live data streams</li>
</ul>
<h4>Spark is easy to use</h4>
<ul>
<li>Provides a general purpose programming model using expressive languages like Scala, Python, and Java.</li>
<li>Existing libraries and API makes it easy to write programs combining batch, streaming, interactive machine learning and complex queries in a single application.</li>
<li>An interactive shell (aka REPL) is available for Python and Scala</li>
<li>Built for performance and reliability;&nbsp;written in Scala and runs on top of Java Virtual Machine (JVM).</li>
<li>Operational and debugging tools from the Java stack are available for programmers.</li>
</ul>
<h4>Getting started with Apache Spark</h4>
<p>The official Apache Spark website provides detailed documentation on&nbsp;how to install <a href="https://spark.apache.org/docs/latest/">Apache Spark</a>. In this&nbsp;blog post, I will assume you already have Spark installed. However, if you wish, I have also&nbsp;created&nbsp;a Docker image of everything you will need to start a Docker container running Apache Spark, along with some other tools and packages used in these blog posts&nbsp;(e.g., R,&nbsp;iPython, Pandas,&nbsp;NumPy,&nbsp;matplotlib,&nbsp;etc.).</p>
<p>If you&nbsp;want to follow along with the examples provided,&nbsp;you can either use your local install of Apache Spark, or&nbsp;you can pull down my Docker image like so (assuming you already have Docker installed on your local machine):</p>

<p><amp-img class="aligncenter size-full wp-image-9689" src="../hs-fs/hubfs/Imported_Blog_Media/5952a7535228784fa3f0be67_apache-spark-p13818.png?width=893&amp;height=50&amp;name=5952a7535228784fa3f0be67_apache-spark-p1.png" alt="" width="893" height="50" srcset="https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7535228784fa3f0be67_apache-spark-p1.png?width=447&amp;height=25&amp;name=5952a7535228784fa3f0be67_apache-spark-p1.png 447w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7535228784fa3f0be67_apache-spark-p1.png?width=893&amp;height=50&amp;name=5952a7535228784fa3f0be67_apache-spark-p1.png 893w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7535228784fa3f0be67_apache-spark-p1.png?width=1340&amp;height=75&amp;name=5952a7535228784fa3f0be67_apache-spark-p1.png 1340w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7535228784fa3f0be67_apache-spark-p1.png?width=1786&amp;height=100&amp;name=5952a7535228784fa3f0be67_apache-spark-p1.png 1786w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7535228784fa3f0be67_apache-spark-p1.png?width=2233&amp;height=125&amp;name=5952a7535228784fa3f0be67_apache-spark-p1.png 2233w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7535228784fa3f0be67_apache-spark-p1.png?width=2679&amp;height=150&amp;name=5952a7535228784fa3f0be67_apache-spark-p1.png 2679w" layout="responsive"></amp-img>Note: The above Docker image size is ~2.66 GB, so it might take a while to download, depending on your Internet speed.</p>
<p>Then start&nbsp;a&nbsp;Docker container from the above&nbsp;image with:</p>

<p><amp-img class="aligncenter size-full wp-image-9690" src="../hs-fs/hubfs/Imported_Blog_Media/5952a77ac190402237b637a7_apache-spark-p2-12746.png?width=900&amp;height=78&amp;name=5952a77ac190402237b637a7_apache-spark-p2-1.png" alt="" width="900" height="78" srcset="https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a77ac190402237b637a7_apache-spark-p2-1.png?width=450&amp;height=39&amp;name=5952a77ac190402237b637a7_apache-spark-p2-1.png 450w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a77ac190402237b637a7_apache-spark-p2-1.png?width=900&amp;height=78&amp;name=5952a77ac190402237b637a7_apache-spark-p2-1.png 900w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a77ac190402237b637a7_apache-spark-p2-1.png?width=1350&amp;height=117&amp;name=5952a77ac190402237b637a7_apache-spark-p2-1.png 1350w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a77ac190402237b637a7_apache-spark-p2-1.png?width=1800&amp;height=156&amp;name=5952a77ac190402237b637a7_apache-spark-p2-1.png 1800w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a77ac190402237b637a7_apache-spark-p2-1.png?width=2250&amp;height=195&amp;name=5952a77ac190402237b637a7_apache-spark-p2-1.png 2250w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a77ac190402237b637a7_apache-spark-p2-1.png?width=2700&amp;height=234&amp;name=5952a77ac190402237b637a7_apache-spark-p2-1.png 2700w" layout="responsive"></amp-img>Note: The above container will have access to files in the directory the&nbsp;Docker&nbsp;command was run from and mounted at `/data`&nbsp;inside the container.&nbsp;Since it is not a good idea to store your&nbsp;datasets inside Docker containers, this blog post will assume the datasets used in this article are found in the same directory as where you ran the above&nbsp;Docker command (see below for details on the datasets in question).</p>
<p>Apache Spark will be installed under `/spark` and all of Spark's binaries/scripts will be in the user path. As such, you can start, say,&nbsp;pyspark&nbsp;by simply executing `pyspark` from your current working directory.</p>
<p><strong>A simple example using Apache Spark&nbsp;MLlib</strong></p>
<p>Logistic Regression is part of a class of machine learning problems, generally referred to as function approximation. Function approximation is a subset of problems that are called â€œsupervised learning problemsâ€. Linear regression is the most common (and basic) algorithm in this class. Logistic regression (a classifier cousin of linear regression) is especially useful for text classification. It is fast, simple to use, and provides optimum or near-optimum performance on the vast majority of predictive analytics problems encountered in datasets with categorical targets (i.e., the target of prediction is a yes/no, true/false, present/absent, etc. outcome). For example, in text classification, we can ask Do the documents in the dataset have a word/phrase or not? The following is a very simple example of using logistic regression for text classification.</p>
<p>Let's pretend we have a very simple dataset where we want to do some basic text document classification. Our dataset consists of a comma-separated values (CSV) file with one text document per line in the file. Our example dataset is just lines that either contain the word "spark" or do not. This will be the&nbsp;target&nbsp;of our&nbsp;MLlib&nbsp;training and will be what we use to create our ML model. Our&nbsp;training&nbsp;dataset has three columns: document ID (`id`), the text of the document (`text`), and a `label` value of&nbsp;1.0 or&nbsp;0.0 for whether or not the line has our&nbsp;target&nbsp;word "spark".</p>

<h4><amp-img class="aligncenter size-full wp-image-9691" src="../hs-fs/hubfs/Imported_Blog_Media/5952a7ec46ee51456f7146a5_apache-spark-p35541.png?width=895&amp;height=188&amp;name=5952a7ec46ee51456f7146a5_apache-spark-p3.png" alt="" width="895" height="188" srcset="https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7ec46ee51456f7146a5_apache-spark-p3.png?width=448&amp;height=94&amp;name=5952a7ec46ee51456f7146a5_apache-spark-p3.png 448w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7ec46ee51456f7146a5_apache-spark-p3.png?width=895&amp;height=188&amp;name=5952a7ec46ee51456f7146a5_apache-spark-p3.png 895w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7ec46ee51456f7146a5_apache-spark-p3.png?width=1343&amp;height=282&amp;name=5952a7ec46ee51456f7146a5_apache-spark-p3.png 1343w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7ec46ee51456f7146a5_apache-spark-p3.png?width=1790&amp;height=376&amp;name=5952a7ec46ee51456f7146a5_apache-spark-p3.png 1790w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7ec46ee51456f7146a5_apache-spark-p3.png?width=2238&amp;height=470&amp;name=5952a7ec46ee51456f7146a5_apache-spark-p3.png 2238w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a7ec46ee51456f7146a5_apache-spark-p3.png?width=2685&amp;height=564&amp;name=5952a7ec46ee51456f7146a5_apache-spark-p3.png 2685w" layout="responsive"></amp-img>The text document classification pipeline we will use has the following workflow:</h4>
<ul>
<li>Training workflow: Input is a set of text documents, where each document is labelled. Stages while training the ML model are:</li>
<li>Split each text document (or lines in our `train.csv` file) into words;</li>
<li>Convert each document's words into a numerical feature vector; and</li>
<li>Create a prediction model using the feature vectors and labels.</li>
<li>Test/prediction workflow: Input is a set of text documents and the goal is to predict a label for each document. Stages while testing or making predictions with the ML model are:</li>
<li>Split each text document (or lines in our `test.csv` file) into words;</li>
<li>Convert each document's words into a numerical feature vector; and</li>
<li>Use the trained model to make predictions on the feature vector.</li>
</ul>
<p>Start up the&nbsp;pyspark&nbsp;REPL (interactive shell):</p>

<p><amp-img class="aligncenter size-full wp-image-9692" src="../hs-fs/hubfs/Imported_Blog_Media/5952a8125228784fa3f0bef8_apache-spark-p4-12c5c.png?width=893&amp;height=49&amp;name=5952a8125228784fa3f0bef8_apache-spark-p4-1.png" alt="" width="893" height="49" srcset="https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a8125228784fa3f0bef8_apache-spark-p4-1.png?width=447&amp;height=25&amp;name=5952a8125228784fa3f0bef8_apache-spark-p4-1.png 447w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a8125228784fa3f0bef8_apache-spark-p4-1.png?width=893&amp;height=49&amp;name=5952a8125228784fa3f0bef8_apache-spark-p4-1.png 893w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a8125228784fa3f0bef8_apache-spark-p4-1.png?width=1340&amp;height=74&amp;name=5952a8125228784fa3f0bef8_apache-spark-p4-1.png 1340w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a8125228784fa3f0bef8_apache-spark-p4-1.png?width=1786&amp;height=98&amp;name=5952a8125228784fa3f0bef8_apache-spark-p4-1.png 1786w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a8125228784fa3f0bef8_apache-spark-p4-1.png?width=2233&amp;height=123&amp;name=5952a8125228784fa3f0bef8_apache-spark-p4-1.png 2233w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a8125228784fa3f0bef8_apache-spark-p4-1.png?width=2679&amp;height=147&amp;name=5952a8125228784fa3f0bef8_apache-spark-p4-1.png 2679w" layout="responsive"></amp-img>Note: The following commands&nbsp;should&nbsp;be run from within the&nbsp;pyspark&nbsp;REPL.&nbsp;The following code is based off of the example scripts provided in the Spark&nbsp;tarball.</p>

<p><amp-img class="aligncenter size-full wp-image-9693" src="../hs-fs/hubfs/Imported_Blog_Media/5952a82e1877e0098f9302a4_apache-spark-p56b03.png?width=630&amp;height=787&amp;name=5952a82e1877e0098f9302a4_apache-spark-p5.png" alt="" width="630" height="787" srcset="https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a82e1877e0098f9302a4_apache-spark-p5.png?width=315&amp;height=394&amp;name=5952a82e1877e0098f9302a4_apache-spark-p5.png 315w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a82e1877e0098f9302a4_apache-spark-p5.png?width=630&amp;height=787&amp;name=5952a82e1877e0098f9302a4_apache-spark-p5.png 630w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a82e1877e0098f9302a4_apache-spark-p5.png?width=945&amp;height=1181&amp;name=5952a82e1877e0098f9302a4_apache-spark-p5.png 945w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a82e1877e0098f9302a4_apache-spark-p5.png?width=1260&amp;height=1574&amp;name=5952a82e1877e0098f9302a4_apache-spark-p5.png 1260w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a82e1877e0098f9302a4_apache-spark-p5.png?width=1575&amp;height=1968&amp;name=5952a82e1877e0098f9302a4_apache-spark-p5.png 1575w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a82e1877e0098f9302a4_apache-spark-p5.png?width=1890&amp;height=2361&amp;name=5952a82e1877e0098f9302a4_apache-spark-p5.png 1890w" layout="responsive"></amp-img>The above simple script should return the following for Spark&nbsp;MLlib&nbsp;predictions for the test documents:</p>

<p><amp-img class="aligncenter size-full wp-image-9694" src="../hs-fs/hubfs/Imported_Blog_Media/5952a84b46ee51456f7146cc_apache-spark-p688d6.png?width=892&amp;height=122&amp;name=5952a84b46ee51456f7146cc_apache-spark-p6.png" alt="" width="892" height="122" srcset="https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a84b46ee51456f7146cc_apache-spark-p6.png?width=446&amp;height=61&amp;name=5952a84b46ee51456f7146cc_apache-spark-p6.png 446w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a84b46ee51456f7146cc_apache-spark-p6.png?width=892&amp;height=122&amp;name=5952a84b46ee51456f7146cc_apache-spark-p6.png 892w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a84b46ee51456f7146cc_apache-spark-p6.png?width=1338&amp;height=183&amp;name=5952a84b46ee51456f7146cc_apache-spark-p6.png 1338w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a84b46ee51456f7146cc_apache-spark-p6.png?width=1784&amp;height=244&amp;name=5952a84b46ee51456f7146cc_apache-spark-p6.png 1784w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a84b46ee51456f7146cc_apache-spark-p6.png?width=2230&amp;height=305&amp;name=5952a84b46ee51456f7146cc_apache-spark-p6.png 2230w, https://www.redapt.com/hs-fs/hubfs/Imported_Blog_Media/5952a84b46ee51456f7146cc_apache-spark-p6.png?width=2676&amp;height=366&amp;name=5952a84b46ee51456f7146cc_apache-spark-p6.png 2676w" layout="responsive"></amp-img>The above output contains the results of using logistic regression with Spark&nbsp;MLlib&nbsp;to make text document classifier predictions. Each line in the output provides the following:</p>
<ul>
<li>The input line (e.g., 4, spark&nbsp;i&nbsp;j&nbsp;k);</li>
<li>The probability that the line does not and does contain the target word (e.g., ~16% does not, ~84% does); and</li>
<li>The prediction made by Spark (1.0 = true; 0.0&nbsp;false)</li>
</ul>
<p>So, for this&nbsp;very simple&nbsp;example, Spark&nbsp;MLlib&nbsp;made perfect predictions (i.e., all documents with the word "spark" in them were correctly labeled).&nbsp;Of course, with such a simple dataset, the results are not that interesting (or useful, really). The idea of this first blog post in the series&nbsp;was to provide an introduction to Apache Spark, along with a "Hello, world"-type example.</p>
<p><a href="index.html" rel="noopener" target="_blank">Part 2</a> of this blog series on Machine Learning will provide a more complicated (and&nbsp;interesting and&nbsp;useful)&nbsp;example of using Apache Spark for Machine Learning.</p><amp-analytics type="googleanalytics"><script type="application/json">{
  "vars": {
    "account": "UA-2098698-1"
  },
  "triggers": {
    "trackPageview": {
      "on": "visible",
      "request": "pageview"
    }
  }
}
</script></amp-analytics></span>
        </div>
        <div class="full-link">
          <a href="apache-spark-for-machine-learning-part-1.html">View full post</a>
        </div>
      </div>
    </div>
    
    <amp-pixel src="../../track.hubspot.com/__ptq2b06.gif?cd=SCREEN_COLOR_DEPTH-bit&amp;cs=DOCUMENT_CHARSET&amp;ln=BROWSER_LANGUAGE&amp;sd=AVAILABLE_SCREEN_WIDTHxAVAILABLE_SCREEN_HEIGHT&amp;v=1.1&amp;iaa=1&amp;k=1&amp;ccu=CANONICAL_URL&amp;r=DOCUMENT_REFERRER&amp;ct=blog-post&amp;t=Apache+Spark+for+Machine+Learning+-+Part+1&amp;pi=12155670922&amp;a=6151115&amp;nc=true&amp;cgi=11355233533&amp;vi=CLIENT_ID(hubspotutk)&amp;ai=CLIENT_ID(amputk)">
    </amp-pixel>
    
  </body>

<!-- Mirrored from www.redapt.com/blog/apache-spark-for-machine-learning-part-1?hs_amp=true by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 23 Dec 2020 06:51:20 GMT -->
</html>
